---
title: "Exercise 9"
output: 
  html_document: 
    keep_md: yes
---

```{r}
#dataset matcars
head(mtcars)
#?mtcars #for full details on the dataset
```

(1) you are thinking to run a linear model with cyl and wt as predictors, mpg as response. Are you allowed to do that? Y/N? Why?

```{r}
attach(mtcars)
cor(cyl, wt) 
#the 2 variables are collinear and cannot be used as predictors in the same model

```

(2) run a regression with x = wt, y = mpg. Plot predictions with 95% CIs (library effects not allowed here).

```{r}

model1 = lm(mpg ~ wt, mtcars)
plot(wt, mpg)
MyData = data.frame(wt = seq(1.5, 5.5, 0.1))
pred = predict(model1, MyData, se = T, type = "response")

lines(MyData$wt, pred$fit, col = 4)    
lines(MyData$wt, pred$fit + 1.96*pred$se.fit, col = 4, lty = 3)
lines(MyData$wt, pred$fit - 1.96*pred$se.fit, col = 4, lty = 3)
```


(3) Are the assumptions of the model met?

```{r}
par(mfrow = c(2, 2))
plot(model1)
par(mfrow = c(1, 1))
#normality does not look a big problem
shapiro.test(model1$residuals)

# the problem here is 1) non linearity and 2) not homogenous residual spread (only positive residuals for small and large fitted values). Problems with cook distance and influencial values.
# No, we do not fully meet model assumptions here.
```

(4) if your answer to question 3 is yes, we are good here.

(5) if your answer to question 3 is no, do something to improve the model fit and better meet the assumptions. Whatever improvements you achieve, decribe it.

```{r}
model2 = lm(mpg ~ wt + I(wt^2), mtcars) #including a quadratic term may help to improve homogeneity
summary(model2)
par(mfrow = c(2, 2))
plot(model2)
par(mfrow = c(1, 1)) 

# compared to model 1, here we improved homogeneity (although it is still bad) and actually we lost the normality of residuals
shapiro.test(model2$residuals)

plot(wt, mpg)
MyData = data.frame(wt = seq(1.5, 5.5, 0.1))
pred = predict(model2, MyData, se = T, type = "response")
lines(MyData$wt, pred$fit, col = 4)    
lines(MyData$wt, pred$fit + 1.96*pred$se.fit, col = 4, lty = 3)
lines(MyData$wt, pred$fit - 1.96*pred$se.fit, col = 4, lty = 3)

# compared to model1, model 2 is a better fit, with an improvement of almost 8 points in AIC
AIC(model1, model2)

# our last resort. transforming the response variable
model3 = lm(log(mpg) ~ wt + I(wt^2), mtcars) 
summary(model3)
par(mfrow = c(2, 2))
plot(model3)
par(mfrow = c(1, 1)) 
# normalty of residuals is back. Homogeneity looks better if compared to previous models. Certainly, this is not the dream model. Adding more predictors and increasing sample size would help a lot here!!



```







