---
title: Stats Cafe - simulations and resampling (in R)
author: "Jochen Fründ, Michael Staab"
date: "January to February 2017"
output:
  html_document:
    keep_md: true
---


----

# Session 1 (18 Jan 2017): Overview
(Jochen Fründ)

## Intro
On overview of statistical methods using simulation or resampling is given. These methods have in common that they simulate sampling (ultimately based on random number generators in computers), rather than relying on mathematical relationships established for known probability distributions.


On the presentation slides, different statistical methods based on simulation and resampling were categorized into four classes
* randomization / permutation (shuffling data, without replacement; useful e.g. for testing differences between groups)
* bootstrap (resampling with replacement; useful e.g. for estimating parameter uncertainty)
* jackknife and cross-validation (leaving out part of the data, sampling without replacement; useful e.g. for estimating prediction uncertainty)
* Monte Carlo (stricter def.) methods (simulating from a given distribution; useful e.g. for validating or understanding model behavior)

Basically, any statistic/index that you calculate from your data can be tested and analysed with such methods (no problem if it has a weird or unknown distribution). For your 'test statistic', you should consider
* does it reflect what you are interested in? (e.g. influence of abundance may or may not be wanted for community similarity)
* is it influenced by sample size ? (e.g. species richness is underestimated in small samples)
The second point is an important issue particularly for bootstrap and jackknife that don't use all of the original data.


```{r, out.width = "400px"}
knitr::include_graphics("figures/OverviewResamplingMethods.png")  # shows an illustration of the differences between sampling methods
```


## R code

A simple starting pointing for R-code may be some invented data:
```{r}
mydata <- 1:20   # some data of unknown distribution (could be an index of insect diversity or an index of crown density, or ...)
mygroups <- rep(c("hardwood","softwood"), 10)
```

For simulation and resampling, the `sample` function is your best friend. Basically, with `replace=TRUE` you can implement bootstrap methods, and with `replace=FALSE` (the default) randomization and jackknife.
A note of caution when using `sample` in functions etc.: if given a single number, it will sample from all numbers in the range from 1 to this number.

```{r}
sample(c(2,3,5), 3) # samples without replacement out of numbers 2, 3 and 5
sample(c(2,3,5), 3, replace=TRUE) # samples with replacement
sample(3, 3, replace=TRUE)  # this is NOT just sampling from the single element 3

```

Another useful advice may be that computer-generated random numbers are just pseudo-random numbers. They do a good job in simulating randomness, but you can get a reproducible example by setting the random seed with `set.seed()`.


Now, I will show a randomization test, a bootstrap example and a jack-knife example.

## Randomization / Permutation

We may be interested in whether the values (let's call them insect diversity) are different between hardwood and softwood.

```{r}
tapply(mydata, mygroups, mean)
groupmeans <- tapply(mydata, mygroups, mean)
groupmeans[1] - groupmeans[2]  # calculates the observed difference
```
Ok, the mean of hardwood is lower than the mean of softwood. But is this significant?
The null hypothesis is that the label hardwood or softwood does not matter for our response variable (index of insect diversity). This can be simulated by randomly assigning these labels.

```{r}
mydata.ran <- sample(mydata, replace=FALSE)
groupmeans.ran <- tapply(mydata.ran, mygroups, mean) # you could also sample mygroups instead of mydata, the idea is to break the association between the two vectors
groupmeans.ran[1] - groupmeans.ran[2]
```

Next would be to do this sampling a lot of times (or take all possible combinations = permutation), to get a null distribution, to which the observed value (`r as.vector(groupmeans[1] - groupmeans[2])`) can be compared.


```{r}
meandif.ran <- function(mydata, mygroups){
  mydata.ran <- sample(mydata, replace=FALSE)
  groupmeans.ran <- tapply(mydata.ran, mygroups, mean)
  groupmeans.ran[1] - groupmeans.ran[2]
}
meandifs.ran <- replicate(5000, meandif.ran(mydata, mygroups))
hist(meandifs.ran, xlab= "difference in means")
abline(v= groupmeans[1] - groupmeans[2], col="red", lwd=2)
```

In this case, the observed difference in means (red line) is right in the middle of randomizations, so if values were the result of real sampling, hardwood and softwood would not be significantly different.



## Bootstrap

If we want to quantify the uncertainty of the overall mean (e.g. to test it against a literature value), we cannot use randomization -- each permutation has the same mean. But we can do this with bootstrap.

```{r}
mydata.ran <- sample(mydata, replace=TRUE)
mean(mydata.ran)
```

```{r}
quantile(replicate(5000, mean(sample(mydata, replace=TRUE))), c(0.025, 0.975))
```
This gives lower and upper confidence limits of the overall mean.


## Jackknife and Cross Validation

These methods have in common that (randomly selected) parts of the data are left out. Leaving out one datapoint is called first-order jackknife:
```{r}
mydata[-(sample(length(mydata), 1))]
```

This can also give an estimate of uncertainty, which of course has to be interpreted differently than the bootstrap confidence limits:

```{r}
quantile(replicate(5000, mean(mydata[-(sample(length(mydata), 1))])), c(0.025, 0.975))
```



## Monte Carlo

Often simulations not just based on `sample`, but use functions `rnorm` (random numbers from a normal distribution), `rpois` (from a Poisson distribution), etc.
For example:

```{r}
hist(rnorm(99, mean=2, sd=1))
```

But also the `sample` function may still be useful. Note that it also has a `prob` argument, which can assign different probabilities to the different elements being sampled.


----

# Session 2 (01 Feb 2017): Permutation / Randomization
(Michael Staab)

This session provided more detailed examples of randomization tests, especially using functions commonly used in community ecology.
See also accompanying slides.


```{r}
# generate some data

xx <- rnorm(n=20, mean=1.6, sd=1)
yy <- rnorm(n=20, mean=1, sd=1)


## xx <- rpois(n=20, lambda=7)	# works also for other data types; try it
## yy <- rpois(n=20, lambda=5)


# assemble the dataset
data <-data.frame(c(xx,yy))
names(data) <- "obs"
data[,"treat"] <- c(rep("x", 20), rep("y", 20))
str(data)
head(data)


# illustrate the data
boxplot(obs ~ treat, names=c("x","y"), cex.axis=1.4, las=1, ylab="Observation",
	cex.lab=1.4, col="grey80", data=data)

plot(density(data$obs[data$treat=="x"]), xlim=c(-3,6), ylim=c(0,0.8), col="red", lwd=3, las=1,
	cex.axis=1.4, cex.lab=1.4)
lines(density(data$obs[data$treat=="y"]), col="blue", lwd=3)
abline(v=mean(data$obs[data$treat=="x"]), col="red", lwd=2, lty=2)
abline(v=mean(data$obs[data$treat=="y"]), col="blue", lwd=2, lty=2)
```

## simple permutation test

```{r}
# we are interested in the differences between the means
mean.obs <- mean(data$obs[data$treat=="x"]) - mean(data$obs[data$treat=="y"])


# how many permutations?
n.perm <- 10000
mean.perm <- rep(0, n.perm)
for(i in 1:n.perm) {					# write a short loop
	
	perm.obs <- sample(data$obs)			# that is the crucial step: sample your data (without replacement, replace=F is default)
	perm.data <- data.frame(perm.obs)		# reassemble the dataset, this is here mostly for illustrative purpose
	perm.data[,"treat"] <- c(data$treat)
	names(perm.data) <- c("obs", "treat")
		
	mean.perm[i] <- mean(perm.data$obs[perm.data$treat=="x"]) - mean(perm.data$obs[perm.data$treat=="y"])
	}

# illustrate what we actually did
plot(density(mean.perm), lwd=3, col="steelblue", las=1, cex.axis=1.4, cex.lab=1.4)	# density of our permutations
abline(v=mean.obs, lwd=3, col='gold')		# this is the observed difference in means
abline(v=mean(mean.perm), lwd=3, lty=2)

p.val <- sum(abs(mean.perm) > abs(mean.obs)) / length(mean.perm)	# two-tailed test
p.val
# ifelse(p.val > 0.5, 1-p.val, p.val)
t.test(xx, yy)		# not so different to a t-test
```


## example for community data

```{r}
require(vegan)

# get the data
data(dune); str(dune)
data(dune.env); str(dune.env)

# simple odination for illustration
nmds_1 <- metaMDS(dune, distance = "bray")
nmds_1

plot(nmds_1, type="n", cex.axis=1.4, cex.lab=1.4, las=1)
points(scores(nmds_1, display=c("sites"))[,1], scores(nmds_1, display=c("sites"))[,2], 
	pch=c(19), col=c("grey50"), cex=1.2)	# add the plots

# influence of the environment
str(dune.env)

# lets have a look at the effect of management
plot(nmds_1, type="n", cex.axis=1.4, cex.lab=1.4, las=1)
points(scores(nmds_1, display=c("sites"))[,1], scores(nmds_1, display=c("sites"))[,2], 
	pch=c(19), col=c("gold", "grey40", "green", "grey70")[dune.env$Management], cex=1.2)	# add the plots
legend("topright", c("Biological","Hobby","Conservation","Standard"), bty="n", cex=1.2, pch=19, col=c("gold","grey40","green","grey70"))

```

## `anosim`: Analysis of Similarities
* rank-based method relying on dissimilarity ranks
* only categories
* limited output

### effect of management?

```{r}
dune.ano <- anosim(dune, grouping=dune.env$Management, permutations = 1000, distance = "bray")
summary(dune.ano) 
```


## alternative `adonis`: Permutational Multivariate Analysis of Variance Using Distance Matrices

```{r}
dune.adonis <- adonis(dune ~ Management, data=dune.env, permutations=1000, dist="bray")
dune.adonis		# be aware: those are pseudo-values (F, R?,...)
summary(dune.adonis) # the output offers a range of parameters that may be of interest

dune.adonis$aov.tab
#plot(density(dune.adonis$f.perms))
dune.adonis$coefficients

### also possible for continuous predictors and interactions
dune.adonis_A1 <- adonis(dune ~ A1 * Management, data=dune.env, permutations=1000, dist="bray")
dune.adonis_A1

str(dune.env)

```

Both methods (`anosim` and `adonis`) allow the incorporation of blocked/nested designs
* data only permuted within their group
* specified by a vector containing categorial info: `strata=data$block`

