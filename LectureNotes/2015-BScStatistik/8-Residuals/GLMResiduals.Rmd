---
title: "Praxis Residuen für normales, binomial und Poisson GLM"
author: "Florian Hartig"
date: "5 Dec 2015"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=6, warning=FALSE, message=FALSE)
```

# Teil 1, Wiederholung, Lineare (Normalverteilte) Regression

### Daten erzeugen

```{r}
x = -20:20
y = (rnorm(length(x), -x^2 + 10* x, 20) + 600) / 600
plot(x,y, xlab = "Schwierigkeit der Vorlesung", ylab = "Aufmerksamkeit")
```


### Fitten die Daten mit einer linearen Funktion

```{r}
fit = glm(y~x)
summary(fit)


plot(x,y, xlab = "Schwierigkeit der Vorlesung", ylab = "Aufmerksamkeit")
abline(fit, col = "red")
```

Ergebnisse anschauen

```{r}
summary(fit)
```

Ein paar Bemerkungen / Erklärungen 

* Ganz oben steht der Modellaufruf
* Danach kommt eine übersicht über die typische Abweichung zwischen Modell und Daten, gemessen durch die Deviance residuals
* Dann die geschätzten Parameter (Estimate), ihre Unsicherheit (Std. Error), und dann die t / p Werte für den Test ob der Parameter signifikant unterschiedlich ist von 0
* Dann der Schätzer für den Dispersion parameter (Dispersion parameter for gaussian family taken to be 0.047039) - Erinnerung: bei der Normalverteilung wird eine Varianz mitgefittet 
* Dann die Null / Residual Deviance. Erinnerung: Deviance = -2 Log Likelihood. Jetzt wird es ein bisschen kompliziert
 * Null Deviance = Deviance(Null) - Deviance(Saturated Model) mit df = df_Sat - df_Null
 * Residual Deviance = Deviance(Proposed) - Deviance(Saturated Model) mit df = df_Sat - df_Null 
 * Null = nur intercept / saturated = 1 parameter pro Datenpunkt, proposed = gefittetes Modell 
 * R2 = Erklärte Varianz ist gleich 1-Residual/Null für eine Normalverteilung
* Am Ende der AIC = Deviance + 2p


### Residuen Plots

so bekommt man alle 4 Residuenplots in einem Plot

```{r}
par(mfrow = c(2,2))
plot(fit)
```

Plots mit Hand

```{r}
par(mfrow = c(1,2))
plot(x, residuals(fit))
hist(residuals(fit))
```

Man kann auch testen ob die Residuen nicht-normalverteilt sind 

```{r}
shapiro.test(residuals(fit))
```

Erklärung sie Vorlesung, ich halte mal nur fest: das sieht nicht gut aus!


### Aktualisiertes Modell

Dann nehmen wir doch mal einen quadratischen Termn dazu

```{r}
fit2 = glm(y~x + I(x^2))
plot(x,y, xlab = "Schwierigkeit der Vorlesung", ylab = "Aufmerksamkeit")
lines(x, predict(fit2), col = "red")
```

Summary anzeigen

```{r}
summary(fit2)
```

Residuen anzeigen

```{r}
par(mfrow = c(2,2))
plot(fit2)
```

Würde ein komplexeres Modell eine deutliche Verbesserung bringen?

```{r}
fit3 <- glm(y~x + I(x^2) + I(x^3) + I(x^4) )

AIC(fit)
AIC(fit2)
AIC(fit3)
```

Nein - zwar wird die residual deviance etwas geringer, aber vom AIC würden wir sagen es gibt keine signifikante Verbesserung!

# Teil 2: Diagnostik für Poisson / Binomial

### Verteilungen

Varianz ändert sich mit steigendem Mittelwert bei der Poisson

```{r}

lambda = c(0.1,1,4,10)
x <- sapply(lambda, function(x)dpois(0:20,x))
barplot(t(x), beside = T, col = 1:4, names = 0:20, main = "Poisson")
legend("topright", legend = lambda, col = 1:5, pch = 16 )

```

und auch bei der binomial 

```{r}

lambda = c(0.05,0.5,0.95)
x <- sapply(lambda, function(x)dbinom(0:20,20,x))
barplot(t(x), beside = T, col = 1:3, names = 0:20, main = "Binomial")
legend("top", legend = lambda, col = 1:5, pch = 16 )

```


### Beispiel mit dem Datensatz von der Donau, siehe letzte Vorlesung


```{r}
load(file = "/Users/Florian/Home/Projekte/Data/Examples/Donau/cleand.Rdata")
```


Nicht empfhelenswert, nur zur Anschauung: Fit der Daten mit einer normalen linearen Regression 

```{r}
fit <- lm(Keimlinge ~  Art * Wasserstand, data = data)
plot(predict(fit),  residuals(fit)/summary(fit)$sigma, xlab = "Modellerwartung", ylab = "Residuum")
abline(h = c(-2,2), lty = 2)
```

Wir sehen Varianzheterogenität / Heteroskedastizität. Variablentransformation kann das etwas rausnehmen (siehe Diskussion über mögliche Transformation [hier](http://stats.stackexchange.com/questions/46418/why-is-the-square-root-transformation-recommended-for-count-data)), aber der qq-plot sieht immer noch nicht gut aus

```{r}
fit <- lm(sqrt(Keimlinge) ~  Art * Wasserstand , data = data)
par(mfrow = c(1,2))
plot(predict(fit),  residuals(fit)/summary(fit)$sigma, xlab = "Modellerwartung", ylab = "Residuum")
abline(h = c(-2,2), lty = 2)
qqnorm(residuals(fit))
qqline(residuals(fit))
```

und ein Test der Residuen in diesem Fall zeigt immer noch eine Verletzung der Annahmen der Normalverteilung

```{r}
shapiro.test(residuals(fit))

```

## Analyse mit Poisson Regression

Also: wir gehen zur Poisson-Regression.

```{r}
fit <- glm(Keimlinge ~  Art * Wasserstand, data = data, family = "poisson")
```

Verschieden Residuen, von oben links nach unten rechts

1. die normalen Residuen -  hier sieht man dass die Varianz zunimmt, aber das ist auch erwartet. Ob sie mehr zunimmt als erwartet sieht man wenn man Person Residuen plottet
2. Pearson - sie sehen dass die Varianz jetzt homogener ist 
3. Deviance
4. Studentized

```{r}
par(mfrow = c(2,2))
plot(predict(fit, type = "response"),  residuals(fit, type = "response"), xlab = "Modellerwartung", ylab = "Residuum", main = "normale Residuen")
plot(predict(fit, type = "response"),  residuals(fit, type = "pearson"), xlab = "Modellerwartung", ylab = "Residuum", main = "Pearson")
plot(predict(fit, type = "response"),  residuals(fit, type = "deviance"), xlab = "Modellerwartung", ylab = "Residuum", main = "Deviance")
plot(predict(fit, type = "response"),  rstudent(fit), xlab = "Modellerwartung", ylab = "Residuum", main = "studentized")

```

### Varianzüberschuss

Pearson is skaliert auf die Standardabweichung. Wir würden ca. 95% der Beobachtungen innerhalb von 2*sd erwarten. Wenn wir uns die Linie einzeichenen dann sehne wir dass wir deutlich mehr Punkte außerhalb haben

```{r}
plot(predict(fit, type = "response"),  residuals(fit, type = "pearson"), xlab = "Modellerwartung", ylab = "Residuum")
abline(h = c(-2,2), lty = 2)
```

Sieht nach Varianzüberschuss / Overdispersion aus. Wir können den Varianzüberschuss auch feststellen durch 

```{r, eval=F}
summary(fit) 
```

Ich hab das nicht ausgegeben weil es so lang ist, aber wenn man unten die residual deviancen anschaut dann sieht man dass residual deviance / degrees of freedom = 1600 / 528 ~= 3, und das ist > 1, also overdispersed. 

Formaler mit einem Test (package AER)

```{r}
library(AER)
dispersiontest(fit)
```

Ja, es gibt zu viel Varianz. Deshalb wählen wir die quasi-poisson Verteilung die das korrigiert. Da die Residual Verteilung die Pearson-Residuen für die quasi-Poisson nicht korrekt macht berechne ich die per Hand:

```{r}
fit <- glm(Keimlinge ~  Art * Wasserstand , data = data, family = "quasipoisson")
erwartung = predict(fit, type = "response")
plot(erwartung,  residuals(fit, type = "response")/sqrt(erwartung*summary(fit)$dispersion) )
abline(h = c(-2,2), lty = 2)
```

Alternative ist neg, Binomial (glm.nb in package MASS, siehe Beispiel [hier](http://www.ats.ucla.edu/stat/r/dae/nbreg.htm))

```{r}
library(MASS)
fit2<- glm.nb(Keimlinge ~  Art * Wasserstand , data = data)
```

Wenn sie summary(fit2) machen sehen sie den dispersion Parameter Theta, für Theta gegen unendlich wird die neg. Binomial gleich der Poisson Verteilung. 

Weitere Möglichkeiten (werden nicht abgefragt).

* overdispersion als ramdom effect, mit glmer in package lme4, fit <- glmer(Keimlinge ~  Art * Wasserstand + (1|replicate), data = data, family = "poisson")
* Wenn zu viele Nullen da sind ein zero-inflated Poisson Modell, zeroinfl in package pscl, siehe [hier](http://www.ats.ucla.edu/stat/r/dae/zipoisson.htm)


# Teil 3: Praxis

## Example 1

Hatten wir ja in der Vorlesung, hier geht es darum wie viele Stücke Futter ein junger Vogel von seinen Eltern bekommt, abhängig von seiner Attraktivität

```{r}
data = read.table("../../../Data/Doorman2013/schnaepper.txt")
plot(stuecke ~ attrakt, data = data)
```


```{r}
fit <- glm(stuecke ~ attrakt, family = poisson, data = data)
summary(fit)
```

Schauen wir mal Pearson an

```{r}
plot(predict(fit, type = "response"), residuals(fit, type = "pearson"))
abline(h = 0)
```

sieht OK aus, noch mal Overdispersion testen

```{r}

summary(fit)
# 18/23
library(MASS)
dispersiontest(fit)
```

Leicht underdispersed, aber nicht signifikant, also müssen wir nichts machen!

## Example 2

Hier wurden Pflanzen mit drei verschiedenen Pflanzengiften behandelt, wir schauen wie viele von von n Planzen (variiert) gestorben sind. Erst mal graphisch

```{r}
data = read.table("../../../Data/Doorman2013/logistic.txt", header = T)
head(data)
library(lattice)
xyplot(dead/n ~ logdose | product, data=data)
```

Die Frage ist: gibt es Unterschiede zwischen den Giften. Ich will hier demonstrieren dass falsche Modellannahmen zu underdisperion führen. Die falsche Annahmen die wir machen ist dass die Mortalitätsrate nur vom Gift abhängt. In Wirklichkeit hängt sie auch von der Dosis ab, aber das lassen wir hier erst mal außer Acht. Dann fitten wir mal das Modell


```{r}
fit <- glm(cbind(dead,n-dead) ~ product, family = binomial, data = data)
```

Ergebnisse anschauen

```{r}
summary(fit)
boxplot(residuals(fit, type = "pearson") ~ data$product)
```

Und, was wir hier sehen ist Varianzheterogenität, und auch ein bisschen Pattern in den Residuen - Gift B hat weniger Varianz als die anderen, und es schent so als geht der Mittelwert runter von A zu C. Wenn wir sowas sehen brauchen wir uns eigentlich gar nich um Overdispersion zu kümment, aber wir hätten auch Overdispersion denn sie sehen wir haben 

Residual = 88 / 48 dgf = dispersion von 2 > 1, d.h. overdispersion. 

Dann nehmen wir doch mal die fehlenden Variable dazu:

```{r}
fit <- glm(cbind(dead,n-dead) ~ product * logdose + I(logdose^2), family = binomial, data = data)
summary(fit)
```

Ich plotte mal Pearson Residuen gegen die Dosis, für alle 3 Gifte extra

```{r}
xyplot(residuals(fit, type = "pearson") ~ logdose | product, data=data)
```

sieht gut aus, aber Sie sehen dass die Werten nicht zwischen -2 und 2 streuen, sondern viel weniger, d.g. underdispersion. Das sieht man auch durch 

Residual = 11 / 44 dgf = dispersion von 0.25 < 1, d.h. underdispersion. 

Ich hatte es ja gesagt: underdispersion ist auch schlecht, denn sie bekommen zu große p-Werte. Wenn Sie die Underdispersion rausnehmen, werden die Schätzer signifikanter.


```{r}
fit <- glm(cbind(dead,n-dead) ~ product * logdose + I(logdose^2), family = quasibinomial, data = data)
summary(fit)
```

Bemerkung: natürlich ist nicht alles korrekt was die Werte signifikanter macht, aber im Fall von Underdispersion ist es so dass das korrektere Modell auch signifikantere Werte liefert. 

Bei Overdispersion werden die Werte weniger signifikant wenn sie Overdispersion korrigeren. Korrigieren müssen Sie trotzdem!


