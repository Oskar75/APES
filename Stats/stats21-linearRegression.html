<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<title></title>

<script src="stats21-linearRegression_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="stats21-linearRegression_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="stats21-linearRegression_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="stats21-linearRegression_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="stats21-linearRegression_files/highlight/default.css"
      type="text/css" />
<script src="stats21-linearRegression_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">




<div id="linear-regression" class="section level1">
<h1>Linear regression</h1>
<div id="simple-linear-regression" class="section level2">
<h2>Simple linear regression</h2>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2>Multiple linear regression</h2>
<p>Multiple linear regression is the term for the situation in which you have multiple predictor variables, but still only one continous response with the same assumptions as before.</p>
<p><a href="http://www.youtube.com/watch?v=q1RD5ECsSB0" target="_blank"> <img src="http://img.youtube.com/vi/q1RD5ECsSB0/0.jpg" alt="Video" /><br/ > Video demonstrating multiple linear regresssion in R </a></p>
<pre class="r"><code>load(&quot;../Data/lung.Rdata&quot;)
head(lung)</code></pre>
<pre><code>##   LungCap Age Height Smoke Gender Caesarean
## 1   6.475   6   62.1    no   male        no
## 2  10.125  18   74.7   yes female        no
## 3   9.550  16   69.7    no female       yes
## 4  11.125  14   71.0    no   male        no
## 5   4.800   5   56.9    no   male        no
## 6   6.225  11   58.7    no female        no</code></pre>
<p>Plot the relationship between age and lung capacity</p>
<pre class="r"><code>attach(lung)
plot(Age,LungCap,main=&quot;Relation between age and lung capacity&quot;
     , col=&quot;green&quot;,las=1, xlab=&quot;Age of the patient&quot;, ylab=&quot;Lung capacity&quot;)
#let&#39;s run the linear model
mod=lm(LungCap~Age)
abline(mod,lwd=2,col=&quot;grey&quot;)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-2.png" alt="plot of chunk unnamed-chunk-2" /></p>
<pre class="r"><code>summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = LungCap ~ Age)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.780 -1.020  0.000  0.979  4.265 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.1469     0.1835    6.25  7.1e-10 ***
## Age           0.5448     0.0142   38.48  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.53 on 723 degrees of freedom
## Multiple R-squared:  0.672,  Adjusted R-squared:  0.671 
## F-statistic: 1.48e+03 on 1 and 723 DF,  p-value: &lt;2e-16</code></pre>
<p>you gotta check: 1) residuals summary 2) estimate for the intercept (null H -&gt; estimate = 0) 3) estimate for the age (slope; null H -&gt; slope = 0 ) 4) residual standard error of 1.526 (measure of variation of observations around regression line) 5) R-squared and adjusted R-Squared 6) F-stat (the null hypothesis implies that all estimates are 0)</p>
<pre class="r"><code># to get the full list of attributes
attributes(mod)</code></pre>
<pre><code>## $names
##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;        
## 
## $class
## [1] &quot;lm&quot;</code></pre>
<pre class="r"><code>#for instance
mod$coefficients</code></pre>
<pre><code>## (Intercept)         Age 
##      1.1469      0.5448</code></pre>
<pre class="r"><code>#ls(mod)
mod$fitted.values[1:50]</code></pre>
<pre><code>##      1      2      3      4      5      6      7      8      9     10 
##  4.416 10.954  9.864  8.775  3.871  7.140  5.506  7.140  9.320  7.140 
##     11     12     13     14     15     16     17     18     19     20 
## 11.499 10.409  7.685  6.595  6.595  8.230  9.320  5.506  7.140  8.775 
##     21     22     23     24     25     26     27     28     29     30 
##  4.416  5.506  9.864  7.140  7.140  7.685  7.685  6.050  3.326 10.954 
##     31     32     33     34     35     36     37     38     39     40 
##  3.326  8.230  8.230  8.230  7.685  6.595  4.416  6.050  7.140 10.409 
##     41     42     43     44     45     46     47     48     49     50 
##  8.775 10.409  5.506  7.685  4.416  7.140  7.140  7.685 10.409  4.961</code></pre>
<pre class="r"><code>plot(Age,LungCap,main=&quot;Relation between age and lung capacity&quot;
     , col=&quot;green&quot;,las=1, xlab=&quot;Age of the patient&quot;, ylab=&quot;Lung capacity&quot;)
abline(mod,lwd=2,col=&quot;grey&quot;)
points(Age,mod$fitted.values, pch=20, col=2)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-31.png" alt="plot of chunk unnamed-chunk-3" /></p>
<pre class="r"><code>plot(Age,mod$residuals,pch=20,col=&quot;blue&quot; )
abline(h=0, lwd=3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-32.png" alt="plot of chunk unnamed-chunk-3" /></p>
<p>letâ€™s plot the regression line</p>
<pre class="r"><code>plot(Age,LungCap,main=&quot;Relation between age and lung capacity&quot;
     , col=&quot;green&quot;,las=1, xlab=&quot;Age of the patient&quot;, ylab=&quot;Lung capacity&quot;)
abline(mod,col=2,lwd=4)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-4.png" alt="plot of chunk unnamed-chunk-4" /></p>
<p>Easier example to appreciate Residuals and Residual Standard error</p>
<pre class="r"><code>x1=c(1,2,3,4,5)
y1=c(1,2,3,100, 200)
plot(x1,y1, xlim=c(0,5), ylim=c(-100,200))
abline(h=0)
mod2=lm(y1~x1); abline(mod2,col=2,lwd=3)
summary(mod2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y1 ~ x1)
## 
## Residuals:
##     1     2     3     4     5 
##  39.0  -9.6 -58.2 -10.8  39.6 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)    -87.6       49.5   -1.77    0.175  
## x1              49.6       14.9    3.32    0.045 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 47.2 on 3 degrees of freedom
## Multiple R-squared:  0.786,  Adjusted R-squared:  0.715 
## F-statistic:   11 on 1 and 3 DF,  p-value: 0.045</code></pre>
<pre class="r"><code>points(x1,mod2$fitted.values, pch=20, col=&quot;blue&quot;,cex=3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-51.png" alt="plot of chunk unnamed-chunk-5" /></p>
<pre class="r"><code>plot(x1,mod2$residuals,pch=20,col=&quot;blue&quot; ); abline(h=0, lwd=3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-52.png" alt="plot of chunk unnamed-chunk-5" /></p>
<pre class="r"><code># z are the residuals of my model
z1=c(39.0,-9.6, -58.2, -10.8, 39.6)

#simple function
SumSquares &lt;- function(x) sum(x^2)
SumSquares(z1)  #6685.2</code></pre>
<pre><code>## [1] 6685</code></pre>
<pre class="r"><code>#residual standard errors for any linear model
ResSE = function(mymodel) sqrt((sum(mymodel$residuals^2)/ mymodel$df.residual)/length(mymodel$df.residual)) 
ResSE(mod2)</code></pre>
<pre><code>## [1] 47.21</code></pre>
<pre class="r"><code>ResSE(mod)</code></pre>
<pre><code>## [1] 1.526</code></pre>
<pre class="r"><code># check the residual standard errors in the model outputs and verify that it is the same. </code></pre>
<p>Time for the model validation: do we meet the main assumptions of the linear regression?</p>
<ol style="list-style-type: decimal">
<li>Y VALUES (OR THE ERRORS) ARE INDEPENDENT (indipendence)</li>
<li>Y VALUES CAN BE EXPRESSED AS A LINEAR FUNCTION OF X (linearity)</li>
<li>VARIATION OF OBSERVATIONS AROUND THE REGRESSION LINE (THE RESIDUAL STANDARD ERROR) IS CONSTANT (homoscedasticity)</li>
<li>FOR A GIVEN X VALUE, Y VALUES (OR THE ERRORS) ARE NORMALLY DISTRIBUTED (normality)</li>
</ol>
<p>In relation to the first assumption, it is important to think about the study design / data collection, if we need to include random effects (see mixed models later on), if we have the potential bias from spatial and temporal autocorrelation.</p>
<p>All the other assumptions can be checked by examining the residuals</p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(mod)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-6.png" alt="plot of chunk unnamed-chunk-6" /></p>
<pre class="r"><code>par(mfrow=c(1,1))</code></pre>
<p>TOP-LEFT PLOT fitted values vs residuals; we should not see patterns here, red line relatively flat</p>
<p>TOP-RIGHT PLOT normality of residuals check; x axis is the expectation for a normal distribution, y axis observed residuals</p>
<p>BOTTOM-LEFT PLOT The third plot (bottom left) this plot is similar to the top left, but on a different scale; it shows the square root of the standardized residuals (where all the values are positive) against the fitted values. If there was a problem, such as the variance increasing with the mean, then the points would be distributed inside a triangular shape, with the scatter of the residuals increasing as the fitted values increase. But there is no such pattern here, which is good.</p>
<p>BOTTOM-RIGHT PLOT This plot shows standardized residuals as a function of leverage, along with Cookâ€™s distance for each of the observed values of the response variable. The point of this plot is to highlight those y values that have the biggest effect on the parameter estimate problem when points are close to cookâ€™s distance contourâ€™</p>
<pre class="r"><code># more checking on linear model residuals, if we are unhappy with QQplots

shapiro.test(mod$residuals)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mod$residuals
## W = 0.999, p-value = 0.9614</code></pre>
<pre class="r"><code>hist(mod$residuals, freq=F,breaks=20)
lines(density(mod$residuals))</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-7.png" alt="plot of chunk unnamed-chunk-7" /></p>
<pre class="r"><code>plot(Age,LungCap,main=&quot;Relation between age and lung capacity&quot;
     , col=&quot;green&quot;,las=1, xlab=&quot;Age of the patient&quot;, ylab=&quot;Lung capacity&quot;)
abline(mod,lwd=2,col=2)
points(Age[114],LungCap[114],pch=20)
points(Age[293],LungCap[293],pch=20)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-8.png" alt="plot of chunk unnamed-chunk-8" /></p>
<pre class="r"><code>detach(lung)</code></pre>
<p>The Lung Capacity linear regression certainly met the assumptions of a linear regression. Are you able to spot a problem then?</p>
<pre class="r"><code>load(&quot;../Data/problems.RData&quot;)</code></pre>
<pre class="r"><code>attach(problems)
plot(x,y)
mod1=lm(y~x,problems)
abline(mod1,col=&quot;red&quot;)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-10.png" alt="plot of chunk unnamed-chunk-10" /></p>
<pre class="r"><code>summary(mod1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = problems)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.273 -0.790  0.185  0.846  3.198 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   8.7441     0.6024   14.52  2.3e-15 ***
## x             0.6911     0.0979    7.06  6.3e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.5 on 31 degrees of freedom
## Multiple R-squared:  0.616,  Adjusted R-squared:  0.604 
## F-statistic: 49.8 on 1 and 31 DF,  p-value: 6.32e-08</code></pre>
<pre class="r"><code>par(mfrow=c(2,2))
plot(mod1)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-11.png" alt="plot of chunk unnamed-chunk-11" /></p>
<pre class="r"><code>par(mfrow=c(1,1)) </code></pre>
<p>Assumption of linearity and homoscedasticity (top-left plot) are hardly met in this example.</p>
<pre class="r"><code>decay &lt;- read.delim(&quot;../Data/Decay.txt&quot;)

#The data we examine in this section are on the decay of a biodegradable plastic in soil: the response, y, is the mass of plastic remaining and the explanatory variable, x, is duration of burial

summary(decay)</code></pre>
<pre><code>##       time          amount     
##  Min.   : 0.0   Min.   :  8.2  
##  1st Qu.: 7.5   1st Qu.: 21.5  
##  Median :15.0   Median : 35.0  
##  Mean   :15.0   Mean   : 42.1  
##  3rd Qu.:22.5   3rd Qu.: 57.5  
##  Max.   :30.0   Max.   :125.0</code></pre>
<pre class="r"><code>attach(decay)
plot(time,amount)
mod3=lm(amount~time)
abline(mod3,lwd=2,col=2)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-121.png" alt="plot of chunk unnamed-chunk-12" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(mod3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-122.png" alt="plot of chunk unnamed-chunk-12" /></p>
<pre class="r"><code>par(mfrow=c(1,1))


# plot1: 
#you get a plot of the residuals against the fitted values (left plot) which 
#shows very pronounced curvature; most of the residuals for intermediate fitted
#values are negative, and the positive residuals are concentrated at the smallest 
#and largest fitted values. Remember, this plot should look like the sky at 
#night, with no pattern of any sort. This suggests systematic inadequacy 
#in the structure of the model. 

#plot 2 -&gt; few problems 

par(mfrow=c(1,1)) 
shapiro.test(mod3$residuals)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mod3$residuals
## W = 0.9214, p-value = 0.0257</code></pre>
<pre class="r"><code>hist(mod3$residuals, freq=F,breaks=20)
lines(density(mod3$residuals))</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-123.png" alt="plot of chunk unnamed-chunk-12" /></p>
<pre class="r"><code>#The third graph is like a positive-valued version of the first graph; 
#it is good for detecting non-constancy of variance (heteroscedasticity), 
#which shows up as a triangular scatter (like   a wedge of cheese). 
#The fourth graph shows a pronounced pattern in the standardized 
#residuals as a function of the leverage. The graph also shows 
#Cooks distance, highlighting
#the identity of particularly influential data points.

plot(time,amount)
abline(mod3,lwd=2,col=2)
points(time[1],amount[1],pch=20,cex=1.5)
points(time[5],amount[5],pch=20,cex=1.5)
points(time[30],amount[30],pch=20,cex=1.5)

points(time,mod3$fitted.values, pch=20, col=&quot;blue&quot;)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-124.png" alt="plot of chunk unnamed-chunk-12" /></p>
<pre class="r"><code>plot(time,mod3$residuals)
abline(h=0, lwd=3)
points(time[mod3$residuals&gt;=0],mod3$residuals[mod3$residuals&gt;=0],pch=20,col=&quot;blue&quot; )
points(time[mod3$residuals&lt;0],mod3$residuals[mod3$residuals&lt;0],pch=20,col=&quot;red&quot; )</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-125.png" alt="plot of chunk unnamed-chunk-12" /></p>
<pre class="r"><code>plot(time,amount) #there is a non-linear trend.. quadratic?

mod4=lm(amount~time+I(time^2))
# abline is no longer working here. 

plot(time,amount)
lines(mod4$fitted.values, type=&quot;l&quot;, lwd=2,lty=3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-131.png" alt="plot of chunk unnamed-chunk-13" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(mod4)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-132.png" alt="plot of chunk unnamed-chunk-13" /></p>
<pre class="r"><code>par(mfrow=c(1,2))

#comparisons mod 3 vs mod4
plot(time,mod3$residuals)
abline(h=0, lwd=3)
points(time[mod3$residuals&gt;=0],mod3$residuals[mod3$residuals&gt;=0],pch=20,col=&quot;blue&quot; )
points(time[mod3$residuals&lt;0],mod3$residuals[mod3$residuals&lt;0],pch=20,col=&quot;red&quot; )

plot(time,mod4$residuals)
abline(h=0, lwd=3)
points(time[mod4$residuals&gt;=0],mod4$residuals[mod4$residuals&gt;=0],pch=20,col=&quot;blue&quot; )
points(time[mod4$residuals&lt;0],mod4$residuals[mod4$residuals&lt;0],pch=20,col=&quot;red&quot; )
#influential points
points(time[1],mod4$residuals[5],pch=20,col=&quot;yellow&quot; )
points(time[5],mod4$residuals[5],pch=20,col=&quot;yellow&quot; )
points(time[3],mod4$residuals[3],pch=20,col=&quot;yellow&quot; )</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-133.png" alt="plot of chunk unnamed-chunk-13" /></p>
<pre class="r"><code>par(mfrow=c(1,1))</code></pre>
<pre class="r"><code>plot(time,amount)
mod5=lm(amount~time+I(time^2)+I(time^3))
lines(mod5$fitted.values, type=&quot;l&quot;, lwd=2,lty=3)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-141.png" alt="plot of chunk unnamed-chunk-14" /></p>
<pre class="r"><code>plot(time,mod5$residuals)
abline(h=0, lwd=3)
points(time[mod5$residuals&gt;=0],mod5$residuals[mod5$residuals&gt;=0],pch=20,col=&quot;blue&quot; )
points(time[mod5$residuals&lt;0],mod5$residuals[mod5$residuals&lt;0],pch=20,col=&quot;red&quot; )
points(time[1],mod5$residuals[1],pch=20,col=&quot;yellow&quot; )
points(time[5],mod5$residuals[5],pch=20,col=&quot;yellow&quot; )</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-142.png" alt="plot of chunk unnamed-chunk-14" /></p>
<pre class="r"><code>par(mfrow=c(2,2))
plot(mod5)</code></pre>
<p><img src="stats21-linearRegression_files/figure-html/unnamed-chunk-143.png" alt="plot of chunk unnamed-chunk-14" /></p>
<pre class="r"><code>par(mfrow=c(1,1))

detach(decay)</code></pre>
<p>+++++++++++++++++ Edited by Simone Ciuti, University of Freiburg, 9/10/2014; Intended for the only purpose of teaching @ Freiburg University; Source: 1) Mike Marin Stat - UBC 2)Mick Crawley - The R Book, 2nd edition. 3) Simone Ciuti simulated data +++++++++++++++++++++++++++++++++++++++++++++++++</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
