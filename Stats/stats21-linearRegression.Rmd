---
output:
  html_document:
    keep_md: yes
    self_contained: no
---
Linear regression
===



## Simple linear regression




## Multiple linear regression

Multiple linear regression is the term for the situation in which you have multiple predictor variables, but still only one continous response with the same assumptions as before. 

<a href="http://www.youtube.com/watch?v=q1RD5ECsSB0" target="_blank">
![Video](http://img.youtube.com/vi/q1RD5ECsSB0/0.jpg)<br/ >
Video demonstrating multiple linear regresssion in R
</a>




```{r}
load("../Data/lung.Rdata")
head(lung)
```



Plot the relationship between age and lung capacity
```{r}
attach(lung)
plot(Age,LungCap,main="Relation between age and lung capacity"
     , col="green",las=1, xlab="Age of the patient", ylab="Lung capacity")
#let's run the linear model
mod=lm(LungCap~Age)
abline(mod,lwd=2,col="grey")
summary(mod)
```

you gotta check:
1) residuals summary
2) estimate for the intercept (null H -> estimate = 0)
3) estimate for the age (slope; null H -> slope = 0 )
4) residual standard error of 1.526 (measure of variation of observations around regression line)
5) R-squared and adjusted R-Squared
6) F-stat (the null hypothesis implies that all estimates are 0)




```{r}
# to get the full list of attributes
attributes(mod)
#for instance
mod$coefficients

#ls(mod)
mod$fitted.values[1:50]

plot(Age,LungCap,main="Relation between age and lung capacity"
     , col="green",las=1, xlab="Age of the patient", ylab="Lung capacity")
abline(mod,lwd=2,col="grey")
points(Age,mod$fitted.values, pch=20, col=2)


plot(Age,mod$residuals,pch=20,col="blue" )
abline(h=0, lwd=3)
```

let's plot the regression line
```{r}
plot(Age,LungCap,main="Relation between age and lung capacity"
     , col="green",las=1, xlab="Age of the patient", ylab="Lung capacity")
abline(mod,col=2,lwd=4)
```


Easier example to appreciate Residuals and Residual Standard error
```{r}
x1=c(1,2,3,4,5)
y1=c(1,2,3,100, 200)
plot(x1,y1, xlim=c(0,5), ylim=c(-100,200))
abline(h=0)
mod2=lm(y1~x1); abline(mod2,col=2,lwd=3)
summary(mod2)
points(x1,mod2$fitted.values, pch=20, col="blue",cex=3)
plot(x1,mod2$residuals,pch=20,col="blue" ); abline(h=0, lwd=3)


# z are the residuals of my model
z1=c(39.0,-9.6, -58.2, -10.8, 39.6)

#simple function
SumSquares <- function(x) sum(x^2)
SumSquares(z1)  #6685.2


#residual standard errors for any linear model
ResSE = function(mymodel) sqrt((sum(mymodel$residuals^2)/ mymodel$df.residual)/length(mymodel$df.residual)) 
ResSE(mod2)
ResSE(mod)

# check the residual standard errors in the model outputs and verify that it is the same. 






```


Time for the model validation: do we meet the main assumptions of the linear regression?

1) Y VALUES (OR THE ERRORS) ARE INDEPENDENT (indipendence)
2) Y VALUES CAN BE EXPRESSED AS A LINEAR FUNCTION OF X (linearity)
3) VARIATION OF OBSERVATIONS AROUND THE REGRESSION LINE
(THE RESIDUAL STANDARD ERROR) IS CONSTANT (homoscedasticity)
4) FOR A GIVEN X VALUE, Y VALUES (OR THE ERRORS) ARE NORMALLY DISTRIBUTED (normality)

In relation to the first assumption, it is important to think about the study design / data collection, if we need to include random effects (see mixed models later on), if we have the potential bias from spatial and temporal autocorrelation. 

All the other assumptions can be checked by examining the residuals


```{r}
par(mfrow=c(2,2))
plot(mod)
par(mfrow=c(1,1))




```




TOP-LEFT PLOT
fitted values vs residuals; we should not see patterns here, red line relatively flat

TOP-RIGHT PLOT
normality of residuals check; x axis is the expectation for a normal distribution, y axis observed residuals

BOTTOM-LEFT PLOT
The third plot (bottom left) this plot is similar to the top left, but on a different scale; it shows the square root of the standardized residuals (where all the values are positive) against the fitted values. If there was a problem, such as the variance increasing with the mean, then the points would be distributed inside a triangular shape, with the scatter of the residuals increasing as the fitted values increase. But there is no such pattern here, which is good.

BOTTOM-RIGHT PLOT
This plot shows standardized residuals as a function of
leverage, along with Cook's distance  for each of the observed values of the response
variable. The point of this plot is to highlight those y values that have the biggest effect on the parameter estimate problem when points are close to cook's distance contour'


```{r}
# more checking on linear model residuals, if we are unhappy with QQplots

shapiro.test(mod$residuals)
hist(mod$residuals, freq=F,breaks=20)
lines(density(mod$residuals))
```


```{r}


plot(Age,LungCap,main="Relation between age and lung capacity"
     , col="green",las=1, xlab="Age of the patient", ylab="Lung capacity")
abline(mod,lwd=2,col=2)
points(Age[114],LungCap[114],pch=20)
points(Age[293],LungCap[293],pch=20)

detach(lung)

```
The Lung Capacity linear regression certainly met the assumptions of a linear regression. Are you able to spot a problem then?

```{r}
load("../Data/problems.RData")
```

```{r}
attach(problems)
plot(x,y)
mod1=lm(y~x,problems)
abline(mod1,col="red")
summary(mod1)
```


```{r}
par(mfrow=c(2,2))
plot(mod1)
par(mfrow=c(1,1)) 
```
Assumption of linearity and homoscedasticity (top-left plot) are hardly met in this example.



```{r}
decay <- read.delim("../Data/Decay.txt")

#The data we examine in this section are on the decay of a biodegradable plastic in soil: the response, y, is the mass of plastic remaining and the explanatory variable, x, is duration of burial

summary(decay)
attach(decay)
plot(time,amount)
mod3=lm(amount~time)
abline(mod3,lwd=2,col=2)

par(mfrow=c(2,2))
plot(mod3)
par(mfrow=c(1,1))


# plot1: 
#you get a plot of the residuals against the fitted values (left plot) which 
#shows very pronounced curvature; most of the residuals for intermediate fitted
#values are negative, and the positive residuals are concentrated at the smallest 
#and largest fitted values. Remember, this plot should look like the sky at 
#night, with no pattern of any sort. This suggests systematic inadequacy 
#in the structure of the model. 

#plot 2 -> few problems 

par(mfrow=c(1,1)) 
shapiro.test(mod3$residuals)
hist(mod3$residuals, freq=F,breaks=20)
lines(density(mod3$residuals))

#The third graph is like a positive-valued version of the first graph; 
#it is good for detecting non-constancy of variance (heteroscedasticity), 
#which shows up as a triangular scatter (like   a wedge of cheese). 
#The fourth graph shows a pronounced pattern in the standardized 
#residuals as a function of the leverage. The graph also shows 
#Cooks distance, highlighting
#the identity of particularly influential data points.

plot(time,amount)
abline(mod3,lwd=2,col=2)
points(time[1],amount[1],pch=20,cex=1.5)
points(time[5],amount[5],pch=20,cex=1.5)
points(time[30],amount[30],pch=20,cex=1.5)

points(time,mod3$fitted.values, pch=20, col="blue")

plot(time,mod3$residuals)
abline(h=0, lwd=3)
points(time[mod3$residuals>=0],mod3$residuals[mod3$residuals>=0],pch=20,col="blue" )
points(time[mod3$residuals<0],mod3$residuals[mod3$residuals<0],pch=20,col="red" )
       


```



```{r}
plot(time,amount) #there is a non-linear trend.. quadratic?

mod4=lm(amount~time+I(time^2))
# abline is no longer working here. 

plot(time,amount)
lines(mod4$fitted.values, type="l", lwd=2,lty=3)


par(mfrow=c(2,2))
plot(mod4)





par(mfrow=c(1,2))

#comparisons mod 3 vs mod4
plot(time,mod3$residuals)
abline(h=0, lwd=3)
points(time[mod3$residuals>=0],mod3$residuals[mod3$residuals>=0],pch=20,col="blue" )
points(time[mod3$residuals<0],mod3$residuals[mod3$residuals<0],pch=20,col="red" )

plot(time,mod4$residuals)
abline(h=0, lwd=3)
points(time[mod4$residuals>=0],mod4$residuals[mod4$residuals>=0],pch=20,col="blue" )
points(time[mod4$residuals<0],mod4$residuals[mod4$residuals<0],pch=20,col="red" )
#influential points
points(time[1],mod4$residuals[5],pch=20,col="yellow" )
points(time[5],mod4$residuals[5],pch=20,col="yellow" )
points(time[3],mod4$residuals[3],pch=20,col="yellow" )
par(mfrow=c(1,1))

```


```{r}

plot(time,amount)
mod5=lm(amount~time+I(time^2)+I(time^3))
lines(mod5$fitted.values, type="l", lwd=2,lty=3)

plot(time,mod5$residuals)
abline(h=0, lwd=3)
points(time[mod5$residuals>=0],mod5$residuals[mod5$residuals>=0],pch=20,col="blue" )
points(time[mod5$residuals<0],mod5$residuals[mod5$residuals<0],pch=20,col="red" )
points(time[1],mod5$residuals[1],pch=20,col="yellow" )
points(time[5],mod5$residuals[5],pch=20,col="yellow" )

par(mfrow=c(2,2))
plot(mod5)
par(mfrow=c(1,1))

detach(decay)
```



+++++++++++++++++
Edited by Simone Ciuti, University of Freiburg, 9/10/2014; 
Intended for the only purpose of teaching @ Freiburg University; 
Source: 1) Mike Marin Stat - UBC 2)Mick Crawley - The R Book, 2nd edition. 3) Simone Ciuti simulated data 
+++++++++++++++++++++++++++++++++++++++++++++++++